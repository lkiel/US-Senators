{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Acquisition Notebook\n",
    "\n",
    "## Students\n",
    "\n",
    "* Team: `18`\n",
    "* Students: `Quentin Bacuet, Ali Alami-Idrissi, Keshav Singh, Leandro Kieliger`\n",
    "* Dataset: `US-Senators`\n",
    "\n",
    "## Description\n",
    "\n",
    "This notebook contains the code necessary to collect data from the ProPublica Congress API. In addition, data undergoes some basic processing steps before being stored in .pickle format."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Required librairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "\n",
    "data_folder = 'data/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the API key\n",
    "\n",
    "The API key should be stored in a text file alongside the project. To obtain the API key, visit https://projects.propublica.org/api-docs/congress-api/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "API_KEY = \"\"\n",
    "\n",
    "with open('api_key.txt') as f:\n",
    "    API_KEY = f.read()\n",
    "\n",
    "HEADERS = {\"X-Api-Key\": API_KEY}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating required folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_folder(path):\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "\n",
    "create_folder(data_folder)\n",
    "create_folder(data_folder + 'committees')\n",
    "create_folder(data_folder + 'senate_members')\n",
    "create_folder(data_folder + 'votes')\n",
    "create_folder(data_folder + 'lobby')\n",
    "create_folder(data_folder + 'bills')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fetching bills\n",
    "\n",
    "Bills can be fetched by querying the following url: \n",
    "https://api.propublica.org/congress/v1/{congress}/senate/bills/introduced.json?offset={offset}\n",
    "\n",
    "* The `congress` parameter is used to specify the congress for which we want to query bills. A congress is a meeting of the American legislative branch which lasts two years. It is composed of two chambers, the senate and the house of representatives. Senators are elected for a period of 6 years.\n",
    "\n",
    "* The `offset` parameter is used to navigate through the results since only 20 results are returned per request."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4680\r"
     ]
    }
   ],
   "source": [
    "bill_str = \"https://api.propublica.org/congress/v1/{congress}/senate/bills/introduced.json?offset={offset}\"\n",
    "\n",
    "bill_list = []\n",
    "more_data_available = True\n",
    "request_offset = 0\n",
    "\n",
    "while more_data_available :\n",
    "    res = requests.get(url = bill_str.format(congress=115, offset = request_offset), headers = HEADERS)\n",
    "    if('results' in res.json()):\n",
    "        \n",
    "        # Print progress status\n",
    "        print(request_offset, end='\\r')\n",
    "        \n",
    "        # Verify whether there might be additional result to query\n",
    "        more_data_available = int(res.json()['results'][0]['num_results']) > 0\n",
    "\n",
    "        if more_data_available:\n",
    "            # Extract results from JSON response\n",
    "            bills = res.json()['results'][0]['bills']\n",
    "            bill_list.append(pd.io.json.json_normalize(bills, record_prefix=True))\n",
    "    else:\n",
    "        print(str(request_offset) + ' - Error: ' + res.json()['error'])\n",
    "    request_offset += 20\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save all bills\n",
    "df = pd.concat(bill_list,sort=True)\n",
    "df.to_csv(data_folder + \"bills/bills.csv\")\n",
    "df.to_pickle(data_folder + \"bills/bills.pickle\")\n",
    "\n",
    "# Save only bills that are considered active. That is, bills that are being considered by at least one committee\n",
    "active_bills = df[(df['active']==1)]\n",
    "active_bills.to_csv(data_folder + \"bills/active_bills.csv\")\n",
    "active_bills.to_pickle(data_folder + \"bills/active_bills.pickle\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fetching co-sponsors for each bill\n",
    "\n",
    "Each bill has a sponsor ID, this is the ID of the senator that initially pushes the bill for consideration. However, a bill can be co-sponsored by multiple senators. To find those co-sponsors we need ot perform additional requests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting cosponsors for bill sres48341\r"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "('results', 'occurred at index 1')",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-fad2c6f2ce03>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     28\u001b[0m sponsored_bills['cosponsors_id'] = sponsored_bills.apply( \n\u001b[0;32m     29\u001b[0m     \u001b[1;32mlambda\u001b[0m \u001b[0mrow\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mextract_cosponsors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcosponsors_for_bill\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'bill_slug'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m     \u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m )\n\u001b[0;32m     32\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\ntds_2018\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self, func, axis, broadcast, raw, reduce, result_type, args, **kwds)\u001b[0m\n\u001b[0;32m   6012\u001b[0m                          \u001b[0margs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6013\u001b[0m                          kwds=kwds)\n\u001b[1;32m-> 6014\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   6015\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6016\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapplymap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\ntds_2018\\lib\\site-packages\\pandas\\core\\apply.py\u001b[0m in \u001b[0;36mget_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    140\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_raw\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    141\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 142\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_standard\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    143\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    144\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_empty_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\ntds_2018\\lib\\site-packages\\pandas\\core\\apply.py\u001b[0m in \u001b[0;36mapply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    246\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    247\u001b[0m         \u001b[1;31m# compute the result using the series generator\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 248\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_series_generator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    249\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    250\u001b[0m         \u001b[1;31m# wrap results\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\ntds_2018\\lib\\site-packages\\pandas\\core\\apply.py\u001b[0m in \u001b[0;36mapply_series_generator\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    275\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    276\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseries_gen\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 277\u001b[1;33m                     \u001b[0mresults\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    278\u001b[0m                     \u001b[0mkeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    279\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-6-fad2c6f2ce03>\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(row)\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;31m# Those results are stored as a new column in the dataframe\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m sponsored_bills['cosponsors_id'] = sponsored_bills.apply( \n\u001b[1;32m---> 29\u001b[1;33m     \u001b[1;32mlambda\u001b[0m \u001b[0mrow\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mextract_cosponsors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcosponsors_for_bill\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'bill_slug'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     30\u001b[0m     \u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m )\n",
      "\u001b[1;32m<ipython-input-6-fad2c6f2ce03>\u001b[0m in \u001b[0;36mcosponsors_for_bill\u001b[1;34m(bill_id, congress)\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[1;31m# Extract results from JSON response\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m     \u001b[0mco_sponsors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'results'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'cosponsors'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[1;31m# Print progress status\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: ('results', 'occurred at index 1')"
     ]
    }
   ],
   "source": [
    "def extract_cosponsors(cosponsor_list):\n",
    "    \"\"\"\n",
    "    Extract the cosponsor IDs from a list of JSONs\n",
    "    \"\"\"\n",
    "    \n",
    "    return [x['cosponsor_id'] for x in cosponsor_list]\n",
    "\n",
    "def cosponsors_for_bill(bill_id, congress=115):\n",
    "    \"\"\"\n",
    "    Get the cosposor data in JSON from a bill ID\n",
    "    \"\"\"\n",
    "    \n",
    "    req_url = \"https://api.propublica.org/congress/v1/{congress}/bills/{bill_id}/cosponsors.json\"\n",
    "    res = requests.get(req_url.format(bill_id=bill_id, congress=congress), headers = HEADERS)\n",
    "    \n",
    "    # Extract results from JSON response\n",
    "    co_sponsors = res.json()['results'][0]['cosponsors']\n",
    "    \n",
    "    # Print progress status\n",
    "    print(\"Getting cosponsors for bill \" + str(bill_id), end=\"\\r\")\n",
    "    \n",
    "    return co_sponsors\n",
    "\n",
    "sponsored_bills = active_bills.copy()\n",
    "\n",
    "# For each bill (row) in the dataframe, return a list of all the cosponsors for that particular bill\n",
    "# Those results are stored as a new column in the dataframe\n",
    "sponsored_bills['cosponsors_id'] = sponsored_bills.apply( \n",
    "    lambda row: extract_cosponsors(cosponsors_for_bill(row['bill_slug'])) \n",
    "    , axis=1\n",
    ")\n",
    "\n",
    "# Save the results\n",
    "sponsored_bills.to_pickle(data_folder + \"/bills/bills_and_sponsors.pickle\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing the sponsoring data\n",
    "\n",
    "This section processes the bill with cosponsors dataframe to store them in a convenient way. The sponsor and cosponsors are merged in a common list and the dataframe is reorganized in a way that each bill is represented by a row and each senator as a column. There is then a one in a particular cell if the corresponding senator sponsored the corresponding bill."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract and merge sponsors for each bill\n",
    "bs = pd.read_pickle(data_folder + \"bills/bills_and_sponsors.pickle\")\n",
    "bs = bs.apply(lambda row: pd.Series([row['bill_id'], row['cosponsors_id'] + [row['sponsor_id']]], index=['bills','sponsors']), axis=1)\n",
    "bs = bs.set_index('bills')\n",
    "bs.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the one-hot encoding for sponsoring information\n",
    "df = bs['sponsors'].str.join('|').str.get_dummies()\n",
    "df = df.transpose()\n",
    "\n",
    "# Save the results\n",
    "df.to_pickle(data_folder + \"member_matrices/member_to_bill_sponsoring.pickle\")\n",
    "\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fetching senate members (congress 80 to 115)\n",
    "\n",
    "Retrieve senate members for each congress and save as a separate file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u = \"https://api.propublica.org/congress/v1/{congress}/senate/members.json\"\n",
    "\n",
    "for i in range(80, 115 + 1):\n",
    "    results = requests.get(url = u.format(congress=i), headers=HEADERS)\n",
    "    df = pd.io.json.json_normalize(results.json()['results'][0]['members'])\n",
    "    df.to_csv(data_folder + \"senate_members/senate_members_{congress}.csv\".format(congress=i))\n",
    "    df.to_pickle(data_folder + \"senate_members/senate_members_{congress}.pickle\".format(congress=i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fetching Committees from senate\n",
    "\n",
    "Retrieve all the committees of the senate for congresses 114 and 115"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Request config\n",
    "u = \"https://api.propublica.org/congress/v1/{congress}/senate/committees.json\"\n",
    "\n",
    "for i in range(114, 115 + 1):\n",
    "    results_committee = requests.get(url = u.format(congress=i), headers=HEADERS)\n",
    "    df = pd.io.json.json_normalize(results_committee.json()['results'][0]['committees'])\n",
    "    df_list = []\n",
    "    \n",
    "    # Extract committee information\n",
    "    for committee_id in df['id']:\n",
    "        subcommittee_id = df[df['id'] == committee_id]['subcommittees']\n",
    "\n",
    "        # Fetch data regarding each subcommittee\n",
    "        for subcommittee in subcommittee_id.values[0]:\n",
    "            results_sub = requests.get(url = subcommittee['api_uri'], headers=HEADERS)\n",
    "            if 'results' in results_sub.json():\n",
    "                df_sub = pd.io.json.json_normalize(results_sub.json()['results'][0]['current_members'])\n",
    "                df_sub['subcomittee'] = subcommittee['id']\n",
    "                df_sub['comittee'] = committee_id\n",
    "                df_list.append(df_sub)\n",
    "\n",
    "    if len(df_list) > 0:\n",
    "        df_merged = pd.concat(df_list)\n",
    "        df_merged.to_csv(data_folder + 'committees/committees_members_{congress}.csv'.format(congress = i))\n",
    "        df_merged.to_pickle(data_folder + 'committees/committees_members_{congress}.pickle'.format(congress = i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Getting voting position by member\n",
    "\n",
    "Retrieve all the votes casted by each senator. For our project we use votes casted by senators of the 115th congress."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_senators = pd.DataFrame()\n",
    "\n",
    "for i in range (115,116):\n",
    "    df = pd.read_pickle(\"data/senate_members/senate_members_{congress}.pickle\".format(congress = i))\n",
    "    df['congress'] = i\n",
    "    raw_senators = pd.concat([raw_senators, df], sort=False)\n",
    "    \n",
    "senators_id = raw_senators['id'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u = \"https://api.propublica.org/congress/v1/members/{member_id}/votes.json?offset={offset}\"\n",
    "\n",
    "import os\n",
    "import json\n",
    "import ast\n",
    "\n",
    "completed_ids = os.listdir(\"data/votes\")\n",
    "\n",
    "for senator_id in senators_id:\n",
    "\n",
    "    if \"votes_{id}.csv\".format(id=senator_id) in completed_ids:\n",
    "        continue\n",
    "        \n",
    "    error_raised = False\n",
    "    votes_list = []\n",
    "    data_available = True\n",
    "    request_offset = 0\n",
    "\n",
    "    while data_available :\n",
    "        res = requests.get(url = u.format(member_id = senator_id, offset = request_offset), headers = HEADERS)\n",
    "        s = re.sub(r'(\\s{2,}|\\n)', ' ', res.text)\n",
    "\n",
    "        jObj = json.loads(s)\n",
    "        \n",
    "        print(json.dumps(jObj, indent=4))\n",
    "                \n",
    "        if(res.status_code == 200):\n",
    "            data_available = int(jObj['results'][0]['num_results']) > 0\n",
    "\n",
    "            if data_available:\n",
    "                # Print progress status\n",
    "                print(str(senator_id) + \" offset: \" + str(request_offset), end='\\r')\n",
    "                \n",
    "                # Extract data from JSON\n",
    "                votes = jObj['results'][0]['votes']\n",
    "                votes_list.append(pd.io.json.json_normalize(votes, record_prefix=True))\n",
    "                \n",
    "        else:\n",
    "            print(str(res.status_code))\n",
    "            error_raised = True\n",
    "            break\n",
    "        \n",
    "        request_offset += 20\n",
    "        \n",
    "    if not error_raised and len(votes_list) > 0:\n",
    "        df = pd.concat(votes_list,sort=False)\n",
    "        df.to_csv(data_folder + \"votes/votes_{id}.csv\".format(id=senator_id), index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fetching Lobbying from senate (unused in project)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "re.compile(\"\\((.*)\\\"([\\w ]+)\\\"(.*)\\)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Request config\n",
    "u = \"https://api.propublica.org/congress/v1/lobbying/latest.json?offset={offset}\"\n",
    "\n",
    "votes_list = []\n",
    "data_available = True\n",
    "request_offset = 0\n",
    "\n",
    "while data_available :\n",
    "    res = requests.get(url = u.format(offset = request_offset), headers = HEADERS)\n",
    "    j  = res.text.replace(\"\\\\\\\"\",\"\").replace(\"\\\\\",\"\").replace(\"\\\")\", \")\").replace(\"(\\\"\", \"(\")\n",
    "\n",
    "    try:\n",
    "        res = json.loads(j)       \n",
    "        if('results' in res):\n",
    "            #print(request_offset)\n",
    "            data_available = int(res['results'][0]['num_results']) > 0\n",
    "\n",
    "            if data_available:\n",
    "                votes = res['results'][0]['lobbying_representations']\n",
    "                votes_list.append(pd.io.json.json_normalize(votes, record_prefix=True))\n",
    "        else:\n",
    "            print(str(request_offset) + ' - Error: ' + res['error'])\n",
    "    except:\n",
    "        print(str(request_offset) + ' - Error: Json File badly encoded')\n",
    "    request_offset += 20\n",
    "    \n",
    "df = pd.concat(votes_list,sort=True)\n",
    "df.to_csv(data_folder + \"lobby/lobby.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting senators portraits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "senators = pd.read_pickle(\"data/processed/processed_senators.pickle\")\n",
    "\n",
    "for senator_id in senators.index:\n",
    "    img_data = requests.get(\"https://theunitedstates.io/images/congress/225x275/\"+senator_id+\".jpg\").content\n",
    "    with open('data/senate_members/'+senator_id+'.jpg', 'wb') as handler:\n",
    "        handler.write(img_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
