{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NTDS'18 milestone 1: network collection and properties\n",
    "[Effrosyni Simou](https://lts4.epfl.ch/simou), [EPFL LTS4](https://lts4.epfl.ch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Students\n",
    "\n",
    "* Team: `18`\n",
    "* Students: ` Quentin Bacuet, Ali Alami-Idrissi, Keshav Singh, Leandro Kieliger`\n",
    "* Dataset: `US-Senators`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rules\n",
    "\n",
    "* Milestones have to be completed by teams. No collaboration between teams is allowed.\n",
    "* Textual answers shall be short. Typically one to three sentences.\n",
    "* Code has to be clean.\n",
    "* You cannot import any other library than we imported.\n",
    "* When submitting, the notebook is executed and the results are stored. I.e., if you open the notebook again it should show numerical results and plots. We won't be able to execute your notebooks.\n",
    "* The notebook is re-executed from a blank state before submission. That is to be sure it is reproducible. You can click \"Kernel\" then \"Restart & Run All\" in Jupyter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objective "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose of this milestone is to start getting acquainted to the network that you will use for this class. In the first part of the milestone you will import your data using [Pandas](http://pandas.pydata.org) and you will create the adjacency matrix using [Numpy](http://www.numpy.org). This part is project specific. In the second part you will have to compute some basic properties of your network. **For the computation of the properties you are only allowed to use the packages that have been imported in the cell below.** You are not allowed to use any graph-specific toolboxes for this milestone (such as networkx and PyGSP). Furthermore, the aim is not to blindly compute the network properties, but to also start to think about what kind of network you will be working with this semester. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We use an additional import as our raw data is over 600Mo uncompressed\n",
    "import zipfile\n",
    "\n",
    "from queue import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1 - Import your data and manipulate them. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  A. Load your data in a Panda dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, you should define and understand what are your nodes, what features you have and what are your labels. Please provide below a Panda dataframe where each row corresponds to a node with its features and labels. For example, in the the case of the Free Music Archive (FMA) Project, each row of the dataframe would be of the following form:\n",
    "\n",
    "\n",
    "| Track   |  Feature 1  | Feature 2 | . . . | Feature 518|  Label 1 |  Label 2 |. . .|Label 16|\n",
    "|:-------:|:-----------:|:---------:|:-----:|:----------:|:--------:|:--------:|:---:|:------:|\n",
    "|         |             |           |       |            |          |          |     |        |\n",
    "\n",
    "It is possible that in some of the projects either the features or the labels are not available. This is OK, in that case just make sure that you create a dataframe where each of the rows corresponds to a node and its associated features or labels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Description\n",
    "Using the US-Senators dataset we have the following characteristics:\n",
    "\n",
    "* Nodes: senators\n",
    "* Edges: similarity\n",
    "* Features: voting position on bills\n",
    "* Labels: political party\n",
    "\n",
    "Note that for simplicity we start by using only data from the 115th congress."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "VOTE_DATA_PATH = '../data/votes/'\n",
    "ZIPPED_VOTES = zipfile.ZipFile(VOTE_DATA_PATH+'votes.zip')\n",
    "\n",
    "vote_data_files = [x.filename for x in ZIPPED_VOTES.infolist() if x.filename.startswith('votes_')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def interpret_position(positions):\n",
    "    r = positions.copy()\n",
    "    r = r.apply(lambda x : 1 if x == \"Yes\" else ( -1 if x == \"No\" else 0 ))\n",
    "    \n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "USEFUL_COLUMNS = ['id','bill.number','congress','member_id','question','position', 'timestamp']\n",
    "\n",
    "def process_vote_file(file_path, since_congress=115):\n",
    "    print(\"Processing vote data for {file}\".format(file=file_path), end='\\r')\n",
    "    ifile = ZIPPED_VOTES.open(file_path)\n",
    "    \n",
    "    # Read data\n",
    "    df = pd.read_csv(ifile)\n",
    "\n",
    "    # We drop entries without bill number as they lead to invalid bill IDs\n",
    "    df = df[df['bill.number'].notna()]\n",
    "    \n",
    "    # We drop entries without roll call value\n",
    "    df = df[df['roll_call'].notna()]\n",
    "    \n",
    "    # As there can be several votes per bill we need to build a unique ID\n",
    "    df['id'] = df['bill.bill_id'].map(str) + \"-\" + df['roll_call'].map(str)\n",
    "\n",
    "    # Some bill IDs and roll call numbers are poorly filled, leading to duplicates\n",
    "    df = df.drop_duplicates('id')\n",
    "    \n",
    "    # Build timestamps\n",
    "    df['timestamp'] = pd.to_datetime(df.date.map(str) + \" \" + df.time.map(str))\n",
    "    \n",
    "    # Keep only useful columns\n",
    "    df = df[USEFUL_COLUMNS]\n",
    "    \n",
    "    # Keep only relevant congresses\n",
    "    df = df[df['congress'] >= since_congress]\n",
    "    \n",
    "    # Convert position to numeric\n",
    "    df['position'] = interpret_position(df['position'])\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NOMINATION_VOTE = \"On the Nomination\"\n",
    "MOTION_VOTE = \"On the Motion\"\n",
    "CLOTURE_MOTION_VOTE = \"On the Cloture Motion\"\n",
    "BILL_PASSAGE = \"On Passage of the Bill\"\n",
    "\n",
    "def build_vote_matrix(questions, data):\n",
    "    \"\"\"\n",
    "    Given a list of questions, build a vote matrix.\n",
    "    Index are senators IDs, columns are vote IDs and values are the respective positions\n",
    "    of the senators with respect to the question (Yes, No, blank or NaN if the senator\n",
    "    did not take part in the vote)\n",
    "    \n",
    "    Data should contain the following columns:\n",
    "        - senators ID (member_id)\n",
    "        - vote ID (id)\n",
    "        - position (position)\n",
    "    \"\"\"    \n",
    "    vote_matrix = data[data['question'].isin(questions)]\n",
    "    vote_matrix = vote_matrix.pivot(columns='id', index='member_id', values='position')\n",
    "    \n",
    "    return vote_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_commities_matrix(raw_commities):\n",
    "    res = raw_commities.copy()\n",
    "    res['pos'] = 1\n",
    "    res = res.drop_duplicates(['id','subcomitee'])\n",
    "    res = res.pivot(columns = 'subcomitee',index='id', values='pos')\n",
    "    res = res.fillna(0)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling data about senators\n",
    "raw_senators = pd.read_csv(\"../data/senate_members/senate_members_115.csv\")\n",
    "\n",
    "# Compiling data about votes\n",
    "df_list = []\n",
    "\n",
    "for filepath in vote_data_files:\n",
    "    vote_data = process_vote_file(filepath)\n",
    "    df_list.append(vote_data)\n",
    "    \n",
    "raw_votes = pd.concat(df_list)\n",
    "raw_commities = pd.read_csv(\"../data/commitees/commitees_115/members.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#features = build_vote_matrix([BILL_PASSAGE], raw_votes).dropna(0)\n",
    "\n",
    "features_vote = build_vote_matrix([BILL_PASSAGE], raw_votes).dropna(0)\n",
    "features_commities = build_commities_matrix(raw_commities).dropna(0)\n",
    "\n",
    "features = features_vote.merge(features_commities, left_index=True, right_index=True)\n",
    "\n",
    "\n",
    "features = features.merge(raw_senators[['id', 'party']], left_index=True, right_on='id').set_index('id')\n",
    "features.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B. Create the adjacency matrix of your network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember that there are edges connecting the attributed nodes that you organized in the dataframe above. The connectivity of the network is captured by the adjacency matrix $W$. If $N$ is the number of nodes, the adjacency matrix is an $N \\times N$ matrix where the value of $W(i,j)$ is the weight of the edge connecting node $i$ to node $j$.  \n",
    "\n",
    "There are two possible scenarios for your adjacency matrix construction, as you already learned in the tutorial by Benjamin:\n",
    "\n",
    "1) The edges are given to you explicitly. In this case you should simply load the file containing the edge information and parse it in order to create your adjacency matrix. See how to do that in the  [graph from edge list]() demo.\n",
    "\n",
    "2) The edges are not given to you. In that case you will have to create a feature graph. In order to do that you will have to chose a distance that will quantify how similar two nodes are based on the values in their corresponding feature vectors. In the [graph from features]() demo Benjamin showed you how to build feature graphs when using Euclidean distances between feature vectors. Be curious and explore other distances as well! For instance, in the case of high-dimensional feature vectors, you might want to consider using the cosine distance. Once you compute the distances between your nodes you will have a fully connected network. Do not forget to sparsify by keeping the most important edges in your network.\n",
    "\n",
    "Follow the appropriate steps for the construction of the adjacency matrix of your network and provide it in the Numpy array ``adjacency`` below: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def euclidean_distance(x,y):\n",
    "    \"\"\"\n",
    "    Given two vectors of the same length, return the euclidean distance between the two vectors.\n",
    "    \"\"\"\n",
    "    return np.sqrt(np.sum(np.power(x-y,2)))\n",
    "\n",
    "def hamming_distance(x,y):\n",
    "    a = x != y\n",
    "    return a.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Kernels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gaussian_kernel(distance_matrix):\n",
    "    \"\"\"\n",
    "    Given a matrix calculate the gaussian kernel of it. The variance is given by the mean of the matrix. \n",
    "    \"\"\"\n",
    "    kernel_width = distance_matrix.mean()\n",
    "    res = np.exp(-distance_matrix**2 / kernel_width**2)\n",
    "    return res\n",
    "\n",
    "def linear_kernel(distance_matrix):\n",
    "    max_adj = np.max(distance_matrix)\n",
    "    min_adj = np.min(distance_matrix)\n",
    "    res = 1 - (distance_matrix - min_adj)/(max_adj-min_adj)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sparsify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sparsify_with_lim(adjacency,limit = 0.9):\n",
    "    \"\"\"\n",
    "    Sparsify a matrix by putting each of element of the adjacency matrix to 0\n",
    "    if it's below the limit.\n",
    "    \"\"\"\n",
    "    res = adjacency.copy()\n",
    "    res[res < limit] = 0\n",
    "    return res\n",
    "\n",
    "def sparsify_with_max_neighbors(adjacency,max_neighbors = 45):\n",
    "    \"\"\"\n",
    "    Sparsify a matrix by adding greedily the links of higher weight such that each node\n",
    "    doesn't have more neighbors than max_neighbors \n",
    "    \"\"\"\n",
    "    number_of_nodes = adjacency.shape[0]    \n",
    "    \n",
    "    index_sort = np.argsort(adjacency,axis=None)[::-1]\n",
    "    flatten_adjacency = adjacency.flatten()\n",
    "    res = np.zeros(adjacency.shape)\n",
    "        \n",
    "    for i in range(number_of_nodes * max_neighbors):\n",
    "        node_1 = index_sort[i] % number_of_nodes\n",
    "        node_2 = int(index_sort[i] / number_of_nodes)\n",
    "\n",
    "        if(np.count_nonzero(res[node_1]) < max_neighbors and np.count_nonzero(res[node_2]) < max_neighbors):\n",
    "            res[node_1,node_2] = flatten_adjacency[index_sort[i]]\n",
    "            res[node_2,node_1] = flatten_adjacency[index_sort[i]]\n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adjacency matrix creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def to_binary_adjacency_matrix(adjacency_matrix):\n",
    "    # Mask the adjacency matrix\n",
    "    masked_adjacency = adjacency_matrix.copy()\n",
    "    masked_adjacency[masked_adjacency > 0] = 1\n",
    "    \n",
    "    return masked_adjacency\n",
    "\n",
    "def get_adjacency_matrix(features_matrix,distance_function,kernel_function,sparsify):\n",
    "    \"\"\"\n",
    "    Get the adjacency matrix of the features by first applying the distance function, \n",
    "    then the kernel_function and finally the sparsify function passed in arguments.\n",
    "    \"\"\"\n",
    "    number_of_nodes = features_matrix.shape[0]\n",
    "    distance_matrix = np.asarray([[distance_function(features_matrix[i],features_matrix[j]) for j in range(number_of_nodes)] for i in range(number_of_nodes)])    \n",
    "    kernel = kernel_function(distance_matrix)\n",
    "    np.fill_diagonal(kernel, 0)\n",
    "    return sparsify(kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_matrix = features.drop('party',1).values\n",
    "#features_matrix = np.asarray([[1,0,0,1],[1,0,0,1],[1,1,0,0],[-1,1,1,-1],[-1,0,0,-1]]) # As an example\n",
    "\n",
    "adjacency = get_adjacency_matrix(features_matrix,euclidean_distance,gaussian_kernel,sparsify_with_max_neighbors)\n",
    "n_nodes = adjacency.shape[0]\n",
    "\n",
    "print('The adjacency matrix: \\n \\n {} \\n \\n'.format(adjacency))\n",
    "print('Number of nodes: {}'.format(n_nodes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Execute the cell below to plot the (weighted) adjacency matrix of your network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "plt.spy(adjacency, markersize=3)\n",
    "plt.title('adjacency matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1\n",
    "\n",
    "What is the maximum number of links $L_{max}$ in a network with $N$ nodes (where $N$ is the number of nodes in your network)? How many links $L$ are there in your collected network? Comment on the sparsity of your network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_links_fully_connected = n_nodes * (n_nodes - 1)/2\n",
    "\n",
    "print('Number of links: {}'.format(np.count_nonzero(adjacency) / 2))\n",
    "print('Total possible number of links: {}'.format(total_links_fully_connected))\n",
    "print('Ratio of links in our network: {}'.format((np.count_nonzero(adjacency) / 2)/total_links_fully_connected))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$L_{max}$ = $\\frac{N \\cdot (N-1)}{ 2} $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2\n",
    "\n",
    "Is your graph directed or undirected? If it is directed, convert it to an undirected graph by symmetrizing the adjacency matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your answer here.**\n",
    "\n",
    "Undirected"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3\n",
    "\n",
    "In the cell below save the features dataframe and the **symmetrized** adjacency matrix. You can use the Pandas ``to_csv`` to save the ``features`` and Numpy's ``save`` to save the ``adjacency``. We will reuse those in the following milestones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features.to_csv('features.csv')\n",
    "np.save('adjacency',adjacency)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4\n",
    "\n",
    "Are the edges of your graph weighted?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your answer here.**\n",
    "\n",
    "Yes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 5\n",
    "\n",
    "What is the degree distibution of your network? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "degree =  np.asarray([np.count_nonzero(adjacency[i]) for i in range(n_nodes)])\n",
    "\n",
    "assert len(degree) == n_nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Execute the cell below to see the histogram of the degree distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = np.ones_like(degree) / float(n_nodes)\n",
    "plt.hist(degree, weights=weights);\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the average degree?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_degree = degree.mean()\n",
    "\n",
    "print('The average degree is: {}'.format(average_degree))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 6\n",
    "\n",
    "Comment on the degree distribution of your network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your answer here.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('There is {} nodes in our graph'.format(n_nodes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 7\n",
    "\n",
    "Write a function that takes as input the adjacency matrix of a graph and determines whether the graph is connected or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def bfs(matrix,starting_node = 0):\n",
    "    \"\"\"\n",
    "    Use the BFS algo to explore the graph. Return the visited_nodes that can be reached from the starting_node.\n",
    "    \"\"\"\n",
    "    neighbors = Queue()\n",
    "    neighbors.put(starting_node)\n",
    "    visisted_nodes = [starting_node]\n",
    "    \n",
    "    while not neighbors.empty():\n",
    "        node = neighbors.get()\n",
    "\n",
    "        for elem in list(np.argwhere(matrix[node])):\n",
    "            if elem not in visisted_nodes:\n",
    "                neighbors.put(elem[0])\n",
    "                visisted_nodes.append(elem[0])\n",
    "            \n",
    "    return np.asarray(visisted_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def connected_graph(adjacency):\n",
    "    \"\"\"Determines whether a graph is connected.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    adjacency: numpy array\n",
    "        The (weighted) adjacency matrix of a graph.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    bool\n",
    "        True if the graph is connected, False otherwise.\n",
    "    \"\"\"\n",
    "    \n",
    "    return len(bfs(adjacency)) == n_nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is your graph connected? Run the ``connected_graph`` function to determine your answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "connected_graph(adjacency)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 8\n",
    "\n",
    "Write a function that extracts the connected components of a graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_components(adjacency):\n",
    "    \"\"\"Find the connected components of a graph.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    adjacency: numpy array\n",
    "        The (weighted) adjacency matrix of a graph.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    list of numpy arrays\n",
    "        A list of adjacency matrices, one per connected component.\n",
    "    \"\"\"\n",
    "    \n",
    "    components = []\n",
    "    nodes = set(range(adjacency.shape[0]))\n",
    "    \n",
    "    while len(nodes) != 0:\n",
    "        start_node = nodes.pop()\n",
    "\n",
    "        component = bfs(adjacency, start_node)\n",
    "        components.append(component)\n",
    "        nodes = nodes.difference(set(component))\n",
    "    \n",
    "    return components\n",
    "\n",
    "\n",
    "# Helper function\n",
    "def find_max_component(adjacency):\n",
    "    components = find_components(adjacency)\n",
    "    return components[np.asarray([len(component) for component in components]).argmax()]\n",
    "\n",
    "def get_adjacency_biggest_component(adjacency):\n",
    "    max_component = find_max_component(adjacency)\n",
    "    return adjacency[np.ix_(max_component,max_component)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many connected components is your network composed of? What is the size of the largest connected component? Run the ``find_components`` function to determine your answer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('There are {} different components in the graph.'.format(len(find_components(adjacency))))\n",
    "print('The biggest component has a size of {}.'.format(len(find_max_component(adjacency))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 9\n",
    "\n",
    "Write a function that takes as input the adjacency matrix and a node (`source`) and returns the length of the shortest path between that node and all nodes in the graph using Dijkstra's algorithm. **For the purposes of this assignment we are interested in the hop distance between nodes, not in the sum of weights. **\n",
    "\n",
    "Hint: You might want to mask the adjacency matrix in the function ``compute_shortest_path_lengths`` in order to make sure you obtain a binary adjacency matrix. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_shortest_path_lengths(adjacency, source):\n",
    "    \"\"\"Compute the shortest path length between a source node and all nodes.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    adjacency: numpy array\n",
    "        The (weighted) adjacency matrix of a graph.\n",
    "    source: int\n",
    "        The source node. A number between 0 and n_nodes-1.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    list of ints\n",
    "        The length of the shortest path from source to all nodes. Returned list should be of length n_nodes.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Your code here.\n",
    "    \n",
    "    number_nodes = adjacency.shape[0]\n",
    "    \n",
    "    visited_nodes = set()\n",
    "    shortest_path_lengths = np.ones(number_nodes) * np.inf\n",
    "    shortest_path_lengths[source] = 0\n",
    "    \n",
    "    while len(visited_nodes) != number_nodes:\n",
    "        sorted_distances = np.argsort(shortest_path_lengths)        \n",
    "        i = 0\n",
    "        \n",
    "        while sorted_distances[i] in visited_nodes:\n",
    "            i += 1\n",
    "\n",
    "        elem_with_smallest_dist = sorted_distances[i]        \n",
    "        visited_nodes.add(elem_with_smallest_dist)\n",
    "        \n",
    "        for neighbor in list(np.argwhere(adjacency[elem_with_smallest_dist])):\n",
    "            if neighbor[0] not in visited_nodes:\n",
    "                shortest_path_lengths[neighbor] = min(\n",
    "                    shortest_path_lengths[neighbor],shortest_path_lengths[elem_with_smallest_dist] + 1)\n",
    "            \n",
    "    return shortest_path_lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_shortest_path_lengths(adjacency,0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 10\n",
    "\n",
    "The diameter of the graph is the length of the longest shortest path between any pair of nodes. Use the above developed function to compute the diameter of the graph (or the diameter of the largest connected component of the graph if the graph is not connected). If your graph (or largest connected component) is very large, computing the diameter will take very long. In that case downsample your graph so that it has 1.000 nodes. There are many ways to reduce the size of a graph. For the purposes of this milestone you can chose to randomly select 1.000 nodes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_diameter(adjacency):\n",
    "    diameter = -1\n",
    "    truncated_adjacency = get_adjacency_biggest_component(adjacency)\n",
    "    \n",
    "    for node in range(truncated_adjacency.shape[0]):\n",
    "        diameter = max(*compute_shortest_path_lengths(truncated_adjacency,node),diameter)\n",
    "\n",
    "    return diameter\n",
    "\n",
    "get_diameter(adjacency)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 11\n",
    "\n",
    "Write a function that takes as input the adjacency matrix, a path length, and two nodes (`source` and `target`), and returns the number of paths of the given length between them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_all_paths(adjacency, length):\n",
    "    \n",
    "     return np.linalg.matrix_power(\n",
    "         to_binary_adjacency_matrix(adjacency), \n",
    "         length\n",
    "     )\n",
    "\n",
    "def compute_paths(adjacency, source, target, length):\n",
    "    \"\"\"Compute the number of paths of a given length between a source and target node.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    adjacency: numpy array\n",
    "        The (weighted) adjacency matrix of a graph.\n",
    "    source: int\n",
    "        The source node. A number between 0 and n_nodes-1.\n",
    "    target: int\n",
    "        The target node. A number between 0 and n_nodes-1.\n",
    "    length: int\n",
    "        The path length to be considered.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    int\n",
    "        The number of paths.\n",
    "    \"\"\"\n",
    "    \n",
    "    return compute_all_paths(adjacency, length)[source][target]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test your function on 5 pairs of nodes, with different lengths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(compute_paths(adjacency, 0, 10, 1))\n",
    "print(compute_paths(adjacency, 0, 10, 2))\n",
    "print(compute_paths(adjacency, 0, 10, 3))\n",
    "print(compute_paths(adjacency, 23, 67, 2))\n",
    "print(compute_paths(adjacency, 15, 93, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 12\n",
    "\n",
    "How many paths of length 3 are there in your graph? Hint: calling the `compute_paths` function on every pair of node is not an efficient way to do it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "We use the same trick as the one used in the compute_paths function but this time we do not select\n",
    "a particular coordinate. It then suffices to sum all the entries in the resulting matrix. Note that it is necessary\n",
    "to divide the result by two because each path will be counted twice. (Once from A to B and once from B to A)\n",
    "\"\"\" \n",
    "compute_all_paths(adjacency, 3).sum() / 2.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 13\n",
    "\n",
    "Write a function that takes as input the adjacency matrix of your graph (or of the largest connected component of your graph) and a node and returns the clustering coefficient of that node. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_clustering_coefficient(adjacency, node):\n",
    "    \"\"\"Compute the clustering coefficient of a node.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    adjacency: numpy array\n",
    "        The (weighted) adjacency matrix of a graph.\n",
    "    node: int\n",
    "        The node whose clustering coefficient will be computed. A number between 0 and n_nodes-1.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        The clustering coefficient of the node. A number between 0 and 1.\n",
    "    \"\"\"\n",
    "    \n",
    "    binary_adj = to_binary_adjacency_matrix(adjacency)  \n",
    "    neighbors = np.nonzero(binary_adj[node]) # Select neighbors of given node\n",
    "\n",
    "    if len(neighbors[0]) > 1:\n",
    "        neighbors = np.squeeze(neighbors)\n",
    "    else:\n",
    "        return np.nan\n",
    "    \n",
    "    neighbors_links = binary_adj[np.ix_(neighbors, neighbors)] # Select only links between neighbors of the given node\n",
    "    \n",
    "    k = len(neighbors)\n",
    "    two_L = np.sum(neighbors_links) # By symmetry, summing over the whole matrix counts each link twice\n",
    "    \n",
    "    if k == 0:\n",
    "        return np.nan\n",
    "    \n",
    "    return two_L / (k * (k-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 14\n",
    "\n",
    "What is the average clustering coefficient of your graph (or of the largest connected component of your graph if your graph is disconnected)? Use the function ``compute_clustering_coefficient`` to determine your answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_clustering_coeff = 0.0\n",
    "n = 0\n",
    "truncated_adjacency = get_adjacency_biggest_component(adjacency)\n",
    "\n",
    "for i in range(len(adjacency)):\n",
    "    clustering_coeff_i = compute_clustering_coefficient(adjacency, i)\n",
    "    if not np.isnan(clustering_coeff_i):\n",
    "        n += 1\n",
    "        total_clustering_coeff += clustering_coeff_i\n",
    "    \n",
    "print(\"The average clustering coefficient is {coeff}\".format(coeff=total_clustering_coeff / float(n)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
