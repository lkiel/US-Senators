{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [NTDS'18] milestone 3: spectral graph theory\n",
    "[ntds'18]: https://github.com/mdeff/ntds_2018\n",
    "\n",
    "[MichaÃ«l Defferrard](http://deff.ch), [EPFL LTS2](https://lts2.epfl.ch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Students\n",
    "\n",
    "* Team: `<your team number>`\n",
    "* Students: `<the name of all students in the team>`\n",
    "* Dataset: `<the dataset you used to complete the milestone>`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rules\n",
    "\n",
    "* Milestones have to be completed by teams. No collaboration between teams is allowed.\n",
    "* Textual answers shall be short. Typically one to two sentences.\n",
    "* Code has to be clean.\n",
    "* You cannot import any other library than we imported.\n",
    "* When submitting, the notebook is executed and the results are stored. I.e., if you open the notebook again it should show numerical results and plots. We won't be able to execute your notebooks.\n",
    "* The notebook is re-executed from a blank state before submission. That is to be sure it is reproducible. You can click \"Kernel\" then \"Restart & Run All\" in Jupyter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objective\n",
    "\n",
    "The goal of this milestone is to get familiar with the graph Laplacian and its spectral decomposition."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0 Load your network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you get a `No module named 'sklearn'` error when running the below cell, install [scikit-learn](https://scikit-learn.org) with `conda install scikit-learn` (after activating the `ntds_2018` environment)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import sparse\n",
    "import scipy.sparse.linalg\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ADJACENCY_PATH = '../data/adjacency_matrices/'\n",
    "ADJACENCY_COSINE_PATH = ADJACENCY_PATH + 'cosine'\n",
    "ADJACENCY_EUC_PATH = ADJACENCY_PATH + 'eucledian'\n",
    "MEMBER_ID_PATH = '../data/member_matrices/member_id_party'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's denote your graph as $\\mathcal{G} = (\\mathcal{V}, \\mathcal{E}, A)$, where $\\mathcal{V}$ is the set of nodes, $\\mathcal{E}$ is the set of edges, $A \\in \\mathbb{R}^{N \\times N}$ is the (weighted) adjacency matrix, and $N = |\\mathcal{V}|$ is the number of nodes.\n",
    "\n",
    "Import the adjacency matrix $A$ that you constructed in the first milestone.\n",
    "(You're allowed to update it between milestones if you want to.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "adjacency =  np.load(ADJACENCY_COSINE_PATH+'.npy')\n",
    "members_parties = np.load(MEMBER_ID_PATH+'.npy')\n",
    "# Removing disconnected nodes\n",
    "node_degrees = np.count_nonzero(adjacency, axis=1)\n",
    "nodes_to_keep = np.nonzero(node_degrees)[0]\n",
    "members_parties = members_parties[nodes_to_keep]\n",
    "adjacency = adjacency[nodes_to_keep,:][:,nodes_to_keep]\n",
    "n_nodes = adjacency.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Graph Laplacian"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1\n",
    "\n",
    "From the (weighted) adjacency matrix $A$, compute both the combinatorial (also called unnormalized) and the normalized graph Laplacian matrices.\n",
    "\n",
    "Note: if your graph is weighted, use the weighted adjacency matrix. If not, use the binary adjacency matrix.\n",
    "\n",
    "For efficient storage and computation, store these sparse matrices in a [compressed sparse row (CSR) format](https://en.wikipedia.org/wiki/Sparse_matrix#Compressed_sparse_row_.28CSR.2C_CRS_or_Yale_format.29)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "D = sparse.csr_matrix(np.diag(adjacency.sum(1)))\n",
    "A = sparse.csr_matrix(adjacency)\n",
    "laplacian_combinatorial = D - A\n",
    "D_half = D.power(-0.5)\n",
    "laplacian_normalized =  D_half @ laplacian_combinatorial @ D_half"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use one of them as the graph Laplacian $L$ for the rest of the milestone.\n",
    "We however encourage you to run the code with both to get a sense of the difference!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(92, 92)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "laplacian = laplacian_combinatorial\n",
    "laplacian.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2\n",
    "\n",
    "Compute the eigendecomposition of the Laplacian $L = U^\\top \\Lambda U$, where the columns $u_k \\in \\mathbb{R}^N$ of $U = [u_1, \\dots, u_N] \\in \\mathbb{R}^{N \\times N}$ are the eigenvectors and the diagonal elements $\\lambda_k = \\Lambda_{kk}$ are the corresponding eigenvalues.\n",
    "\n",
    "Make sure that the eigenvalues are ordered, i.e., $0 = \\lambda_1 \\leq \\lambda_2 \\leq \\dots \\leq \\lambda_N$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "eigenvalues,eigenvectors =  scipy.linalg.eig(laplacian.todense())\n",
    "\n",
    "eigenvectors = np.real(eigenvectors)\n",
    "eigenvalues = np.real(eigenvalues)\n",
    "indexes = np.argsort(eigenvalues)\n",
    "eigenvalues = eigenvalues[indexes]\n",
    "eigenvectors = eigenvectors[:,indexes]\n",
    "assert eigenvectors.shape == (n_nodes, n_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.04848048e-15, 8.84561510e-15, 6.57234495e-01, 8.87519272e-01,\n",
       "       2.63443947e+00, 3.89017791e+00, 4.59311500e+00, 6.31067867e+00,\n",
       "       1.26454566e+01, 1.36408947e+01, 1.81130489e+01, 1.95034564e+01,\n",
       "       2.12218926e+01, 2.25012666e+01, 2.25472999e+01, 2.45791406e+01,\n",
       "       2.59247520e+01, 2.66669637e+01, 2.70647330e+01, 2.84090938e+01,\n",
       "       2.92533114e+01, 2.93297356e+01, 2.96502383e+01, 3.02420235e+01,\n",
       "       3.02824855e+01, 3.07442414e+01, 3.13052708e+01, 3.23301221e+01,\n",
       "       3.24836890e+01, 3.25460722e+01, 3.30288308e+01, 3.30973946e+01,\n",
       "       3.36995635e+01, 3.38117240e+01, 3.46276215e+01, 3.47778804e+01,\n",
       "       3.50869130e+01, 3.54563560e+01, 3.54653248e+01, 3.56839383e+01,\n",
       "       3.58189342e+01, 3.58710190e+01, 3.59519006e+01, 3.60861444e+01,\n",
       "       3.61370150e+01, 3.62994971e+01, 3.64968294e+01, 3.65703635e+01,\n",
       "       3.66345273e+01, 3.68857610e+01, 3.68898323e+01, 3.69518239e+01,\n",
       "       3.70006969e+01, 3.70999308e+01, 3.71584912e+01, 3.72169600e+01,\n",
       "       3.74116495e+01, 3.74952318e+01, 3.75022183e+01, 3.75545099e+01,\n",
       "       3.80258780e+01, 3.80258780e+01, 3.80990514e+01, 3.81469910e+01,\n",
       "       3.82235262e+01, 3.83528907e+01, 3.86641100e+01, 3.87807591e+01,\n",
       "       3.89327195e+01, 3.90640564e+01, 3.91296026e+01, 3.91296026e+01,\n",
       "       3.93643927e+01, 3.97493216e+01, 4.03758947e+01, 4.05640227e+01,\n",
       "       4.07902904e+01, 4.08347086e+01, 4.13058767e+01, 4.14262764e+01,\n",
       "       4.14710495e+01, 4.16623032e+01, 4.17451251e+01, 4.26424405e+01,\n",
       "       4.27383082e+01, 4.28144811e+01, 4.28845130e+01, 4.35134891e+01,\n",
       "       4.38087524e+01, 4.39603038e+01, 4.39603038e+01, 4.39603038e+01])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eigenvalues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(92, 92)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eigenvectors.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Justify your choice of eigensolver."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your answer here.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3\n",
    "\n",
    "We can write $L = S S^\\top$. What is the matrix $S$? What does $S^\\top x$, with $x \\in \\mathbb{R}^N$, compute?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "S is the incidence matrix of size number number of nodes X number of edges. For the undirected weighted case, we first choose an arbibtrary orientation and ordering for each edges. Then for the ith column of S, if the ith edge is going in the node j, we set the jth element of the row to the square root of the weight and for the out going edges we set it to the negative square root of the weight. Hence each column only has two elements (as an edge has only two nodes).\n",
    "\n",
    "$S^â¤x$ with $x \\in \\mathbb{R}^N$ will compute a vector with a lenght of the number of edges.\n",
    "\n",
    "We can get that the kth element of this vector is $(S^â¤x)_k = \\sqrt{W_{ij}} \\cdot (x_i - x_j) $ , with k such that the kth edge is $e = (v_j,v_i)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also calculated S to verify that $L = S S^\\top$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges_index = np.nonzero(np.triu(adjacency))\n",
    "n_edges = edges_index[0].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "S = np.zeros((n_nodes,n_edges))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in range(n_edges):\n",
    "    i,j = edges_index[0][idx],edges_index[1][idx]\n",
    "    S[i,idx] =   np.sqrt(adjacency[i,j])\n",
    "    S[j,idx] = - np.sqrt(adjacency[i,j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.allclose(S @ S.T, (D - A).todense())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4\n",
    "\n",
    "Show that $\\lambda_k = \\| S^\\top u_k \\|_2^2$, where $\\| \\cdot \\|_2^2$ denotes the squared Euclidean norm (a.k.a. squared $L^2$ norm)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As $(S^â¤x)_k = \\sqrt{W_{ij}} \\cdot (x_i - x_j) $ then $\\| S^\\top u_k \\|_2^2 = \\sum_{e=\\{v_j,v_i\\}} (\\sqrt{W_{ij}} \\cdot (u_{k_i} - u_{k_j}))^2 = \\sum_{e=\\{v_j,v_i\\}}  W_{ij} \\cdot  (u_{k_i} - u_{k_j})^2 = u_k^T \\cdot L \\cdot u_k = \\lambda_k \\cdot u_k^T \\cdot u_k = \\lambda_k$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What does the quantity $\\| S^\\top x \\|_2^2$ tell us about $x$?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If $\\| S^\\top x \\|_2^2$ is close to an eigenvalue, this mean that x is close to it's associated eigenvector."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 5\n",
    "\n",
    "What is the value of $u_0$, both for the combinatorial and normalized Laplacians?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_u0(laplacian):\n",
    "    eigenvalues,eigenvectors = scipy.linalg.eig(laplacian)\n",
    "    index = np.argmin(eigenvalues)\n",
    "    return eigenvectors[:,index]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combinatorial u0 : \n",
      " [ 0.14787731  0.14787731 -0.01842379  0.14787731 -0.01842379  0.14787731\n",
      "  0.14787731 -0.01842379 -0.01842379 -0.01842379 -0.01842379 -0.01842379\n",
      " -0.01842379  0.14787731  0.14787731  0.14787731  0.14787731 -0.01842379\n",
      "  0.14787731 -0.01842379  0.14787731  0.14787731 -0.01842379 -0.01842379\n",
      " -0.01842379  0.14787731 -0.01842379  0.14787731  0.14787731 -0.01842379\n",
      "  0.14787731  0.14787731  0.14787731  0.14787731 -0.01842379  0.14787731\n",
      "  0.14787731  0.14787731 -0.01842379 -0.01842379  0.14787731 -0.01842379\n",
      " -0.01842379 -0.01842379  0.14787731  0.14787731  0.14787731 -0.01842379\n",
      " -0.01842379 -0.01842379  0.14787731 -0.01842379  0.14787731 -0.01842379\n",
      "  0.14787731 -0.01842379  0.14787731 -0.01842379  0.14787731 -0.01842379\n",
      " -0.01842379 -0.01842379 -0.01842379 -0.01842379  0.14787731 -0.01842379\n",
      "  0.14787731 -0.01842379  0.14787731  0.14787731  0.14787731  0.14787731\n",
      " -0.01842379 -0.01842379  0.14787731 -0.01842379 -0.01842379  0.14787731\n",
      " -0.01842379  0.14787731  0.14787731  0.14787731 -0.01842379  0.14787731\n",
      " -0.01842379 -0.01842379  0.14787731 -0.01842379 -0.01842379 -0.01842379\n",
      " -0.01842379  0.14787731] \n",
      "\n",
      "Normalized u0 : \n",
      " [-1.48333270e-01 -1.51254874e-01 -5.92622694e-17 -1.60629260e-01\n",
      " -2.72907080e-17 -1.63370955e-01 -1.68531261e-01 -1.99459661e-17\n",
      " -2.10922300e-17 -2.07763512e-17 -2.19751591e-17 -2.22479268e-17\n",
      " -2.06633148e-17 -1.53909436e-01 -2.67213459e-02 -1.54826258e-01\n",
      " -1.63729286e-01 -2.19404622e-17 -1.53313576e-01 -2.06633155e-17\n",
      " -1.67071948e-01 -5.92473429e-02 -2.14135134e-17 -2.17457285e-17\n",
      " -1.84303784e-17 -9.85897625e-02 -2.06553666e-17 -1.63714916e-01\n",
      " -1.63161379e-01 -2.15801483e-17 -2.62579024e-02 -1.60631203e-01\n",
      " -1.58238393e-01 -1.62631783e-01 -1.69020257e-17 -1.62438644e-01\n",
      " -1.65014064e-01 -1.17744541e-01 -2.15725176e-17 -2.00084751e-17\n",
      " -1.65859922e-01 -1.92376586e-17 -2.11924334e-17 -2.03752148e-17\n",
      " -1.64902498e-01 -1.49065512e-01 -1.54459513e-01 -2.19858416e-17\n",
      " -2.08726511e-17 -2.08980864e-17 -1.51925710e-01 -2.15356071e-17\n",
      " -1.28949764e-01 -1.88249512e-17 -1.66166163e-01 -1.37356284e-17\n",
      " -1.55870124e-01 -1.93274299e-17 -5.26390912e-02 -2.17457285e-17\n",
      " -2.03319163e-17 -1.78320947e-17 -1.74745864e-17 -2.08193283e-17\n",
      " -1.63378505e-01 -2.08980864e-17 -1.67047380e-01 -2.23131803e-17\n",
      " -1.66166163e-01 -1.29350676e-01 -1.54955932e-01 -1.66343884e-01\n",
      " -8.59939925e-18 -2.23131803e-17 -1.61787731e-01 -2.08980864e-17\n",
      " -1.77713276e-17 -1.63833079e-01 -2.04971296e-17 -4.54175547e-02\n",
      " -1.50001580e-01 -1.69692247e-01 -2.12351068e-17 -1.65629260e-01\n",
      " -2.14468878e-17 -2.14565303e-17 -1.68653294e-01 -1.61320958e-17\n",
      " -2.23131803e-17 -2.06633155e-17 -1.78495657e-17 -1.65740117e-01] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "u0_combinatorial = get_u0(laplacian_combinatorial.todense())\n",
    "u0_normalized = get_u0(laplacian_normalized.todense())\n",
    "\n",
    "print(\"Combinatorial u0 : \\n {} \\n\".format(u0_combinatorial))\n",
    "print(\"Normalized u0 : \\n {} \\n\".format(u0_normalized))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the course, we also know that the eigenvalues of the combinatorial laplacian is 0. Hence the vector with only 1 is also a possible $u_0$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.allclose(laplacian_combinatorial @ np.ones(n_nodes),np.zeros(n_nodes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the same reasoning as above as: $L \\cdot \\mathbb{1} = \\lambda \\cdot \\mathbb{1}$, with $\\lambda = 0$. \n",
    "\n",
    "We have that:\n",
    "\n",
    "$L_{norm} \\cdot d^{0.5} = D^{-0.5} \\cdot L \\cdot D^{-0.5} \\cdot d^{0.5} = D^{-0.5} \\cdot L\\cdot \\mathbb{1} = \\mathbb{0} = \\lambda \\cdot \\mathbb{1}$, with $d$ the degree vector.\n",
    "\n",
    "Hence the degree vector, where each element is squared is also the first eigenvector of the normalized laplacian."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.allclose(laplacian_normalized @ (np.sqrt(adjacency.sum(1))),np.zeros(n_nodes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 6\n",
    "\n",
    "Look at the spectrum of the Laplacian by plotting the eigenvalues.\n",
    "Comment on what you observe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x201d0a347f0>]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD8CAYAAABn919SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x201d09117b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(eigenvalues)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your answer here.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many connected components are there in your graph? Answer using the eigenvalues only."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As seen above $L \\cdot \\mathbb{1} = \\lambda \\cdot \\mathbb{1} = \\mathbb{0}$. Hence the null space has dimension 1. So we can conclude as the null space dimension is equal to the number of connected components that there is only 1 connected component in our graph."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is there an upper bound on the eigenvalues, i.e., what is the largest possible eigenvalue? Answer for both the combinatorial and normalized Laplacians."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The largest possible eigenvalue for the normalized Laplacian is 2.\n",
    "\n",
    "The largest possible eigenvalue for the combinatorial Laplacian is the trace of D (sum of all weights). Indeed as $Tr(L) = \\sum_i \\lambda_i$ and that by construction $Tr(L) = Tr(D)$, the largest eigenvalue cannot exceed this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Laplacian eigenmaps\n",
    "\n",
    "*Laplacian eigenmaps* is a method to embed a graph $\\mathcal{G}$ in a $d$-dimensional Euclidean space.\n",
    "That is, it associates a vector $z_i \\in \\mathbb{R}^d$ to every node $v_i \\in \\mathcal{V}$.\n",
    "The graph $\\mathcal{G}$ is thus embedded as $Z \\in \\mathbb{R}^{N \\times d}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 7\n",
    "\n",
    "What do we use Laplacian eigenmaps for? (Or more generally, graph embeddings.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Laplacian eigenmaps are used to reduce the dimensionality of each datapoint such that similar points in high dimension are embedded close to each other in lower dimension."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 8\n",
    "\n",
    "Embed your graph in $d=2$ dimensions with Laplacian eigenmaps.\n",
    "Try with and without re-normalizing the eigenvectors by the degrees, then keep the one your prefer.\n",
    "\n",
    "**Recompute** the eigenvectors you need with a partial eigendecomposition method for sparse matrices.\n",
    "When $k \\ll N$ eigenvectors are needed, partial eigendecompositions are much more efficient than complete eigendecompositions.\n",
    "A partial eigendecomposition scales as $\\Omega(k |\\mathcal{E}|$), while a complete eigendecomposition costs $\\mathcal{O}(N^3)$ operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_laplacian = D_half @ laplacian @ D_half"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "partial_eigenvalues,partial_eigenvectors = sparse.linalg.eigs(normalized_laplacian,3,which ='SM',v0=np.ones(n_nodes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "indexes = np.argsort(partial_eigenvalues)\n",
    "partial_eigenvalues = partial_eigenvalues[indexes]\n",
    "partial_eigenvectors = partial_eigenvectors[:,indexes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = partial_eigenvectors[:,1:3].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = np.real(embedding)\n",
    "embedding_degree = np.reshape(adjacency.sum(1),(n_nodes,1)) * embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the nodes embedded in 2D. Comment on what you see."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The embedding from the eigenvector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x201d47d5160>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX8AAAD8CAYAAACfF6SlAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAAFRdJREFUeJzt3X2MXNd9n/HnZ3Ipr1wnS0YSRdHe\nUEYZ1nLkivDUdiMoaCIxdILYJFQ1duAm6zYGUfivBihRCmybIE0gumzrBGiBgGFa0GkaC1IVkrCd\n0BQVG0UaOV6Gohi5YFZSI0vLBSlLomtb62hN/frH3lVXy9nXM7szy/N8gMF9O3PPOTPD79w5915u\nZCaSpLq8pdsNkCStPMNfkipk+EtShQx/SaqQ4S9JFTL8JalChr8kVcjwl6QKGf6SVKG13W7AbG64\n4YbcsmVLt5shSavK6dOnv5mZN85XrmfDf8uWLQwPD3e7GZK0qkTEcwsp57CPJFXI8JekChn+klQh\nw1+SKmT4S1KFDH9JqpDhL0kVMvwlqUKGvyRVqGfv8JWk6Y6eGeXgifNcuDzOLQP97N25jd3bN3e7\nWauW4S9pTr0QukfPjHL/I+cYn7gCwOjlcX75wScYfu5lfn337SvalmuFwz6SZjUVuqOXx0kmQ/f+\nR85x9Mzoirbj4InzbwT/lAR+//FvrHhbrhUe+UuaVbvQHZ+4wsET51f06P/C5fG26xNWvC3tzPx1\n9BN/50a+8OQYr7w6AUAEZMLmHhquMvylReqFYZCVMlvozrZ+udwy0M/oCrVl6v0dvTz+RmgDrL++\nj1/58Huueq8//jt/xp8+8/Iby6OXx/lvj3/jTWWm9jH1ywno+mfG8Nc1rdNB3W7sebH/mFfTl8ds\noXvLQH/xvhfzOuzduY1ffvAJcpY2dsrM9zenVfjKqxP88wef4P5HnuR7E68zcH0f3/neBBOvL66O\nbvxyasfw1zWrE0E9U+kwyHK0aTnt3bntTe0F6O9bw96d24r2u9jXYff2zQw/9zK///g33vQF0Km2\n/Orxp7g8PrGg8uNN2k8N6SzFSv9yascTvrpmzRXUS1U6DLIcbVpOu7dv5oF7b2fzQD/B5Jj1A/fe\nXvxFtZTX4dd3385nPnpHR9ty9Mwoex86u+Dg75RO/lpZqo4c+UfEh4DfAtYAhzPzwIzt1wGfBd4H\nvAR8NDP/uhN1l/jAb5zk4rdfW3D5AK5ft4bvvnblqm0D/X3c+PZ1jFz67pvWb25O/nz+7NgbH7DZ\nxg5nKh0eWE3DC8thOcarS4dBemUMfTF2b9/c8c/NUl+HTrfl4InzTLzebjBp+QQU/1rphOIj/4hY\nA/xn4KeB24Cfj4jbZhT7JeCVzPzbwGeAT5fWW2qxwQ+TVxa0C36Ay+MTVwU//P+TP9OPLF55dYK9\nD5+d8xK10kvseuUSvW6aLZBLjrr27txGf9+aN61bzNDDcrRpNeqV12Glv3QD+PgHB3viIKwTwz7v\nB57OzGcz8zXgc8CuGWV2AUea+YeBuyMiOlD3ki02+Dtt4krO+RO3dHhgtQ0vLIfSoG6ndBhkOdq0\nGvXK67CSXzabB/r5zEfv6Jmb0jox7LMZeH7a8gvAB2Yrk5nfj4hvAT8EfHN6oYjYA+wBGBwc7EDT\nettcRx2lwwOrcXih06YCudNDXyVDD8vVptWmV16HvTu3sfehswse+lm3Jrh+3Vq+NT7BwPV9ZE7+\n6p9+SehAfx+/+pH5h3W7rRPh3+4IfuYruZAyZOYh4BBAq9Va2YG4LpjrqKN0bHk5L9FbTZZjvLpU\nL7apG3rhdZiqv93VPsFkSPXSjVmd1InwfwF457TldwAXZinzQkSsBX4QeJku2vj2dV0d+ulbE3P+\nxC29xG65LtGTrjW98CXUDZ0Y8/8asDUibo2IdcDHgOMzyhwHhpr5+4DHMrOrR/Zf3b+DjW9ft6jn\nBPC2dWvabhvo72PrTW+7av3mgX7+8QcHGejve2Pd+uv7OHjf353zA1c6trxcl+hJujZEJzI4In4G\n+E0mL/X8L5n5GxHxa8BwZh6PiLcCvwdsZ/KI/2OZ+exc+2y1Wjk8PFzcNkmqSUSczszWfOU6cp1/\nZn4R+OKMdf9m2vz3gH/UibokSeW8w1eSKmT4S1KFDH9JqpDhL0kVMvwlqUKGvyRVyPCXpAoZ/pJU\nIcNfkipk+EtShQx/SaqQ4S9JFTL8JalChr8kVagj/6WzJNXs6JnRrv894sUy/CVpCY6eGW37t39H\nL49z/yPnAHr6C8BhH0lapKNnRtn70Nmrgn/K+MQVDp44v8KtWpyi8I+IDRFxMiJGmun6Wcr9cURc\njojPl9QnSb3g4InzTLw+95/AvXB5fIVaszSlR/77gFOZuRU41Sy3cxD4hcK6JKknLCTYbxnoX4GW\nLF1p+O8CjjTzR4Dd7Qpl5ing24V1SVJPmC/Y+/vWsHfnthVqzdKUhv/GzBwDaKY3lewsIvZExHBE\nDL/44ouFTZOk5bF35zb63hJttw309/HAvbf39MleWMDVPhHxKHBzm037O92YzDwEHAJotVpzD6hJ\nUpdMBfv0q33WX9/Hr3z4PT0f+lPmDf/MvGe2bRFxMSI2ZeZYRGwCLnW0dZLUo3Zv37xqgr6d0mGf\n48BQMz8EHCvcnyRpBZSG/wFgR0SMADuaZSKiFRGHpwpFxP8EHgLujogXImJnYb2SpAJFd/hm5kvA\n3W3WDwOfnLZ8V0k9kqTO8g5fSaqQ4S9JFTL8JalChr8kVcjwl6QKGf6SVCHDX5IqZPhLUoUMf0mq\nkOEvSRUy/CWpQoa/JFXI8JekChn+klQhw1+SKmT4S1KFisI/IjZExMmIGGmm69uUuSMi/iwinoqI\nJyPioyV1SpLKlR757wNOZeZW4FSzPNOrwC9m5nuADwG/GREDhfVKkgqUhv8u4EgzfwTYPbNAZv5V\nZo408xeAS8CNhfVKkgqUhv/GzBwDaKY3zVU4It4PrAOeKaxXklRg3j/gHhGPAje32bR/MRVFxCbg\n94ChzHx9ljJ7gD0Ag4ODi9m9JGkR5g3/zLxntm0RcTEiNmXmWBPul2Yp9wPAF4B/lZmPz1HXIeAQ\nQKvVyvnaJklamtJhn+PAUDM/BBybWSAi1gF/CHw2Mx8qrE+S1AGl4X8A2BERI8COZpmIaEXE4abM\nzwE/DnwiIp5oHncU1itJKhCZvTm60mq1cnh4uNvNkKRVJSJOZ2ZrvnLe4StJFTL8JalChr8kVcjw\nl6QKGf6SVCHDX5IqZPhLUoUMf0mqkOEvSRUy/CWpQoa/JFXI8JekChn+klQhw1+SKmT4S1KFDH9J\nqpDhL0kVKgr/iNgQEScjYqSZrm9T5ocj4nTz5xufioh/VlKnJKlc6ZH/PuBUZm4FTjXLM40BP5aZ\ndwAfAPZFxC2F9UqSCpSG/y7gSDN/BNg9s0BmvpaZf9MsXteBOiVJhUqDeGNmjgE005vaFYqId0bE\nk8DzwKcz80JhvZKkAmvnKxARjwI3t9m0f6GVZObzwHub4Z6jEfFwZl5sU9ceYA/A4ODgQncvSVqk\necM/M++ZbVtEXIyITZk5FhGbgEvz7OtCRDwF3AU83Gb7IeAQQKvVyvnaJklamtJhn+PAUDM/BByb\nWSAi3hER/c38euBO4HxhvZKkAqXhfwDYEREjwI5mmYhoRcThpsy7ga9GxFngK8C/z8xzhfVKkgrM\nO+wzl8x8Cbi7zfph4JPN/EngvSX1SJI6y8suJalChr8kVcjwl6QKGf6SVCHDX5IqZPhLUoUMf0mq\nkOEvSRUy/CWpQoa/JFXI8JekChn+klQhw1+SKmT4S1KFDH9JqpDhL0kVMvwlqUJF4R8RGyLiZESM\nNNP1c5T9gYgYjYj/VFKnJKlc6ZH/PuBUZm4FTjXLs/m3TP4NX0lSl5WG/y7gSDN/BNjdrlBEvA/Y\nCHypsD5JUgeUhv/GzBwDaKY3zSwQEW8B/gOwt7AuSVKHrJ2vQEQ8CtzcZtP+BdbxKeCLmfl8RMxX\n1x5gD8Dg4OACdy9JWqx5wz8z75ltW0RcjIhNmTkWEZuAS22K/X3groj4FPC3gHUR8Z3MvOr8QGYe\nAg4BtFqtXGgnJEmLM2/4z+M4MAQcaKbHZhbIzI9PzUfEJ4BWu+CXJK2c0jH/A8COiBgBdjTLREQr\nIg6XNk6StDwiszdHV1qtVg4PD3e7GZK0qkTE6cxszVfOO3wlqUKGvyRVyPCXpAoZ/pJUIcNfkipk\n+EtShQx/SaqQ4S9JFTL8JalChr8kVcjwl6QKGf6SVCHDX5IqZPhLUoUMf0mqkOEvSRUy/CWpQkXh\nHxEbIuJkRIw00/WzlLsSEU80j+MldUqSypUe+e8DTmXmVuBUs9zOeGbe0Tw+UlinJKlQafjvAo40\n80eA3YX7kyStgNLw35iZYwDN9KZZyr01IoYj4vGI8AtCkrps7XwFIuJR4OY2m/Yvop7BzLwQEe8C\nHouIc5n5TJu69gB7AAYHBxexe0nSYswb/pl5z2zbIuJiRGzKzLGI2ARcmmUfF5rpsxHxZWA7cFX4\nZ+Yh4BBAq9XKBfVAkrRopcM+x4GhZn4IODazQESsj4jrmvkbgDuBrxfWK0kqUBr+B4AdETEC7GiW\niYhWRBxuyrwbGI6Is8CfAAcy0/CXpC6ad9hnLpn5EnB3m/XDwCeb+f8F3F5SjySps7zDV5IqZPhL\nUoUMf0mqkOEvSRUy/CWpQoa/JFXI8JekChn+klQhw1+SKmT4S1KFDH9JqpDhL0kVMvwlqUKGvyRV\nyPCXpAoZ/pJUIcNfkipUFP4RsSEiTkbESDNdP0u5wYj4UkT874j4ekRsKalXklSm9Mh/H3AqM7cC\np5rldj4LHMzMdwPvBy4V1itJKlAa/ruAI838EWD3zAIRcRuwNjNPAmTmdzLz1cJ6JUkFSsN/Y2aO\nATTTm9qU+RHgckQ8EhFnIuJgRKxpt7OI2BMRwxEx/OKLLxY2TZI0m7XzFYiIR4Gb22zav4g67gK2\nA98AHgQ+AfzuzIKZeQg4BNBqtXKB+5ckLdK84Z+Z98y2LSIuRsSmzByLiE20H8t/ATiTmc82zzkK\nfJA24S9JWhmlwz7HgaFmfgg41qbM14D1EXFjs/yTwNcL65UkFSgN/wPAjogYAXY0y0REKyIOA2Tm\nFeBfAKci4hwQwO8U1itJKjDvsM9cMvMl4O4264eBT05bPgm8t6QuSVLneIevJFXI8JekChn+klQh\nw1+SKmT4S1KFDH9JqpDhL0kVMvwlqUKGvyRVyPCXpAoZ/pJUIcNfkipk+EtShYr+V09pNTh6ZpSD\nJ85z4fI4twz0s3fnNnZv39ztZkldZfjrmnb0zCj3P3KO8YkrAIxeHuf+R84B+AWgqjnso2vawRPn\n3wj+KeMTVzh44nyXWiT1BsNf17QLl8cXtV6qRVH4R8SGiDgZESPNdH2bMj8REU9Me3wvInaX1Cst\n1C0D/YtaL9Wi9Mh/H3AqM7cCp5rlN8nMP8nMOzLzDib/ePurwJcK65UWZO/ObfT3rXnTuv6+Nezd\nuW1Z6z16ZpQ7DzzGrfu+wJ0HHuPomdFlrU9arNITvruAf9DMHwG+DPzLOcrfB/xRZr5aWK+0IFMn\ndVfyah9PMms1iMxc+pMjLmfmwLTlVzLzqqGfadsfA/5jZn5+lu17gD0Ag4OD73vuueeW3DapW+48\n8Bijbc4pbB7o50/3/WQXWqSaRMTpzGzNV27eI/+IeBS4uc2m/Yts0CbgduDEbGUy8xBwCKDVai39\nW0nqIk8yazWYN/wz857ZtkXExYjYlJljTbhfmmNXPwf8YWZOLKGd0qpxy0B/2yN/TzKrl5Se8D0O\nDDXzQ8CxOcr+PPAHhfVJPa9bJ5mlxSgN/wPAjogYAXY0y0REKyIOTxWKiC3AO4GvFNYn9bzd2zfz\nwL23s3mgn2ByrP+Be2/3ZK96StEJ3+XUarVyeHi4282QpFVloSd8vcNXkipk+EtShQx/SaqQ4S9J\nFTL8JalChr8kVcjwl6QKGf6SVCHDX5Iq1LN3+EbEi8C1/H863wB8s9uN6JJa+15rv8G+r2Tffzgz\nb5yvUM+G/7UuIoYXcgv2tajWvtfab7Dvvdh3h30kqUKGvyRVyPDvnkPdbkAX1dr3WvsN9r3nOOYv\nSRXyyF+SKmT4L6OI2BARJyNipJmun6XcUFNmJCKGpq3/ckScj4gnmsdNK9f6xYuIDzXtfToi9rXZ\nfl1EPNhs/2rzF96mtt3frD8fETtXst2dsNS+R8SWiBif9h7/9kq3vdQC+v7jEfEXEfH9iLhvxra2\nn/3VorDvV6a978dXrtWNzPSxTA/g3wH7mvl9wKfblNkAPNtM1zfz65ttXwZa3e7HAvu6BngGeBew\nDjgL3DajzKeA327mPwY82Mzf1pS/Dri12c+abvdphfq+BfjLbvdhmfu+BXgv8FngvmnrZ/3sr4ZH\nSd+bbd/pZvs98l9eu4AjzfwRYHebMjuBk5n5cma+ApwEPrRC7euk9wNPZ+azmfka8Dkm+z/d9Nfj\nYeDuiIhm/ecy828y8/8ATzf7Wy1K+r7azdv3zPzrzHwSeH3Gc1f7Z7+k711n+C+vjZk5BtBM2w3b\nbAaen7b8QrNuyn9tfhb+6x4Pi/n68aYymfl94FvADy3wub2spO8At0bEmYj4SkTctdyN7bCS966G\n930ub42I4Yh4PCLaHRguq7UrXeG1JiIeBW5us2n/QnfRZt3UJVgfz8zRiHg78D+AX2Dy52Mvmqsf\n85VZyHN7WUnfx4DBzHwpIt4HHI2I92Tm/+10I5dJyXtXw/s+l8HMvBAR7wIei4hzmflMh9o2L4/8\nC2XmPZn5o20ex4CLEbEJoJlearOLF4B3Tlt+B3Ch2fdoM/028N/p7aGQWfvRrkxErAV+EHh5gc/t\nZUvuezPU9RJAZp5mcgz5R5a9xZ1T8t7V8L7PKjOn/p0/y+T5ve2dbNx8DP/ldRyYuoJhCDjWpswJ\n4KciYn1zNdBPASciYm1E3AAQEX3AzwJ/uQJtXqqvAVsj4taIWMfkSc2ZVzBMfz3uAx7LyTNfx4GP\nNVfE3ApsBf58hdrdCUvue0TcGBFrAJojwK1MnvhcLRbS99m0/ewvUzuXw5L73vT5umb+BuBO4OvL\n1tJ2un3G/Fp+MDmmewoYaaYbmvUt4PC0cv+UyZOcTwP/pFn3NuA08CTwFPBb9PgVMMDPAH/F5NHr\n/mbdrwEfaebfCjzU9PPPgXdNe+7+5nnngZ/udl9Wqu/AP2ze37PAXwAf7nZflqHvf4/Jo+TvAi8B\nT0177lWf/dX0WGrfgR8DzjXv+zngl1a67d7hK0kVcthHkipk+EtShQx/SaqQ4S9JFTL8JalChr8k\nVcjwl6QKGf6SVKH/B2I10ceCXpW3AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x201d0944978>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(embedding[:,0],embedding[:,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The embedding scales by the degree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x201d483f630>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD8CAYAAAB+UHOxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nqigDQJIqygCQpIoyACSpov4/SzF5AwSll+QAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x201d47ab6a0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(embedding_degree[:,0],embedding_degree[:,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we expected we can clearly see two clusters and some outliers. This depict the fact that there are two main parties (Republicans and Democrats) and some independant parties."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What does the embedding $Z \\in \\mathbb{R}^{N \\times d}$ preserve?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The embedding that we obtain from the Laplacian eigenmaps is optimal, in the sense that it is the best locality-preserving mapping.\n",
    "\n",
    "Indeed as we are minimizing (without the trivial solution):\n",
    "$$arg \\; min_{y_1,...,y_N} \\sum_{i~j} W(i, j) \\cdot ||y_i - y_j||^2_2$$\n",
    "\n",
    "We will preserve closness,as small distance between two points i and j will imply big weight $w_{ij}$. Hence in the minimisation process $y_i$ and $y_j$ will have to be close to each other, such that $||y_i - y_j||^2_2$ is small to reduce the impact of $w_{ij}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Spectral clustering\n",
    "\n",
    "*Spectral clustering* is a method to partition a graph into distinct clusters.\n",
    "The method associates a feature vector $z_i \\in \\mathbb{R}^d$ to every node $v_i \\in \\mathcal{V}$, then runs [$k$-means](https://en.wikipedia.org/wiki/K-means_clustering) in the embedding space $\\mathbb{R}^d$ to assign each node $v_i \\in \\mathcal{V}$ to a cluster $c_j \\in \\mathcal{C}$, where $k = |\\mathcal{C}|$ is the number of desired clusters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 10\n",
    "\n",
    "Choose $k$ and $d$. How did you get to those numbers?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "assuming that we have 2 distinct groups of republican and democrats, we should try k = 2 , or k = 3 to account for independent candidates. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 11\n",
    "\n",
    "1. Embed your graph in $\\mathbb{R}^d$ as $Z \\in \\mathbb{R}^{N \\times d}$.\n",
    "   Try with and without re-normalizing the eigenvectors by the degrees, then keep the one your prefer.\n",
    "1. If you want $k=2$ clusters, partition with the Fiedler vector. For $k > 2$ clusters, run $k$-means on $Z$. Don't implement $k$-means, use the `KMeans` class imported from scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Your code here.\n",
    "def gen_kmeans(n_clusters,n_features,data,random_state):\n",
    "    data = data[:,-1*n_features:]\n",
    "    means = KMeans(n_clusters=n_clusters, random_state=0).fit(data)\n",
    "    return means.labels_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 12\n",
    "\n",
    "Use the computed cluster assignment to reorder the adjacency matrix $A$.\n",
    "What do you expect? What do you observe?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Your code here.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your answer here.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 13\n",
    "\n",
    "If you have ground truth clusters for your dataset, compare the cluster assignment from spectral clustering to the ground truth.\n",
    "A simple quantitative measure is to compute the percentage of nodes that have been correctly categorized.\n",
    "If you don't have a ground truth, qualitatively assess the quality of the clustering.\n",
    "\n",
    "Ground truth clusters are the \"real clusters\".\n",
    "For example, the genre of musical tracks in FMA, the category of Wikipedia articles, the spammer status of individuals, etc.\n",
    "Look for the `labels` in the [dataset descriptions](https://github.com/mdeff/ntds_2018/tree/master/projects/README.md)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Your code here.\n",
    "def compare_truth(kmeans_labels,original_labels):\n",
    "    #return accuracy, assign the first R to first label{0,1,2} in kmeans, find next unassigned value and assign it to 'D' \n",
    "    #rest to 'I'\n",
    "    first_R_pos = np.where(original_labels == 'R')[0][0]\n",
    "    first_D_pos = np.where(original_labels == 'D')[0][0]\n",
    "    label_at_first_R_pos = kmeans_labels[first_R_pos]\n",
    "    \n",
    "    kmeans_l_copy = np.copy(kmeans_labels).astype(str)\n",
    "    kmeans_l_copy[kmeans_labels == label_at_first_R_pos] = 'R'\n",
    "    \n",
    "    remaining = np.where(kmeans_l_copy[kmeans_l_copy != 'R' ])[0]\n",
    "    label_at_first_D_pos = label_at_first_R_pos\n",
    "    for i in remaining:\n",
    "        if(not(kmeans_labels[i] == label_at_first_R_pos) and (original_labels[i] == 'D' )):\n",
    "            label_at_first_D_pos = kmeans_labels[i]\n",
    "            \n",
    "    kmeans_l_copy[kmeans_labels == label_at_first_D_pos] = 'D'\n",
    "    kmeans_l_copy[(kmeans_labels != label_at_first_R_pos) & (kmeans_labels != label_at_first_D_pos)] = 'I'\n",
    "    return np.sum(kmeans_l_copy == original_labels.flatten())/len(kmeans_labels)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing kmeans with eigenvectors,best accuracy 0.5 for 0 eigenvectors\n",
      "computing kmeans with original features,accuracy 0.8695652173913043 and best seed 483556\n",
      "(1, 'R') (1, 'R') (2, 'D') (1, 'R') (2, 'D') (1, 'R') (1, 'R') (2, 'D') (2, 'D') (2, 'D') (2, 'D') (2, 'D') (2, 'D') (1, 'R') (0, 'R') (1, 'R') (1, 'R') (2, 'D') (1, 'R') (2, 'D') (1, 'R') (0, 'R') (2, 'D') (2, 'D') (2, 'D') (0, 'R') (2, 'D') (1, 'R') (1, 'R') (2, 'D') (0, 'R') (1, 'R') (1, 'R') (1, 'R') (0, 'D') (1, 'R') (1, 'R') (1, 'R') (2, 'D') (2, 'D') (1, 'R') (2, 'D') (2, 'D') (2, 'D') (1, 'R') (1, 'R') (1, 'R') (2, 'D') (2, 'I') (2, 'D') (1, 'R') (2, 'D') (1, 'R') (2, 'D') (1, 'R') (0, 'D') (1, 'R') (2, 'D') (0, 'R') (2, 'D') (2, 'D') (0, 'D') (2, 'D') (2, 'D') (1, 'R') (2, 'D') (1, 'R') (2, 'D') (1, 'R') (1, 'R') (1, 'R') (1, 'R') (0, 'I') (2, 'D') (1, 'R') (2, 'D') (2, 'D') (1, 'R') (2, 'D') (0, 'R') (1, 'R') (1, 'R') (2, 'D') (1, 'R') (2, 'D') (2, 'D') (1, 'R') (0, 'D') (2, 'D') (2, 'D') (0, 'D') (1, 'R')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def get_best_seed(n_clusters,n_features,data,original_labels,n_tries):\n",
    "    accs = []\n",
    "    tries = np.random.randint(low=1, high=1e6, size=n_tries)\n",
    "    for i  in tries:\n",
    "        accs.append(compare_truth(gen_kmeans(n_clusters,n_features,data,i),original_labels))\n",
    "    \n",
    "    accs_ary = np.array(accs)\n",
    "    index_max = np.argmax(accs_ary)\n",
    "    return accs_ary[index_max],tries[index_max]\n",
    "        \n",
    "    \n",
    "accuracies =[]\n",
    "for i in range(1,92):\n",
    "    accuracies.append(compare_truth(gen_kmeans(3,i,eigenvectors,0),members_parties))\n",
    "accs_array = np.array(accuracies)\n",
    "index_max = np.argmax(accs_array)\n",
    "print('computing kmeans with eigenvectors,best accuracy {} for {} eigenvectors'.format(np.max(accs_array),index_max))\n",
    "best_acc,best_seed = get_best_seed(3,93,adjacency,members_parties,100)\n",
    "print('computing kmeans with original features,accuracy {} and best seed {}'.format(best_acc,best_seed))\n",
    "print(*zip(gen_kmeans(3,93,adjacency,best_seed),members_parties.flatten()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 14\n",
    "\n",
    "Plot the cluster assignment (one color per cluster) on the 2D embedding you computed above with Laplacian eigenmaps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Your code here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 15\n",
    "\n",
    "Why did we use the eigenvectors of the graph Laplacian as features? Could we use other features for clustering?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your answer here.**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
